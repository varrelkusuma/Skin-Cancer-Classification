{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm = pd.read_csv('C:/Users/ravee/Jupyter/Skin-Cancer-Classification/data/glcm3.csv', header=None)\n",
    "lbp = pd.read_csv('C:/Users/ravee/Jupyter/Skin-Cancer-Classification/data/lbp3.csv', header=None)\n",
    "dataset = pd.concat([lbp, glcm], axis = 1, ignore_index = True)\n",
    "X = dataset.iloc[:, 0:50].values\n",
    "Y = dataset.iloc[:, 50].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation of Naive Bayes\n",
    "# Fitting Naive Bayes to the training set\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60, 10,  9],\n",
       "       [28, 21, 11],\n",
       "       [27,  7, 12]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set result\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm2 = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5272306553128472\n"
     ]
    }
   ],
   "source": [
    "# Applying K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = nb, X = X_train, y = y_train, cv = 10)\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.75      0.63        40\n",
      "           2       0.38      0.19      0.25        32\n",
      "           3       0.43      0.43      0.43        21\n",
      "\n",
      "    accuracy                           0.48        93\n",
      "   macro avg       0.45      0.46      0.43        93\n",
      "weighted avg       0.46      0.48      0.45        93\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.82      0.70        39\n",
      "           2       0.75      0.55      0.63        33\n",
      "           3       0.33      0.25      0.29        20\n",
      "\n",
      "    accuracy                           0.60        92\n",
      "   macro avg       0.56      0.54      0.54        92\n",
      "weighted avg       0.60      0.60      0.58        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.79      0.67        39\n",
      "           2       0.72      0.39      0.51        33\n",
      "           3       0.35      0.35      0.35        20\n",
      "\n",
      "    accuracy                           0.55        92\n",
      "   macro avg       0.55      0.51      0.51        92\n",
      "weighted avg       0.58      0.55      0.54        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.85      0.69        39\n",
      "           2       0.59      0.39      0.47        33\n",
      "           3       0.43      0.30      0.35        20\n",
      "\n",
      "    accuracy                           0.57        92\n",
      "   macro avg       0.54      0.51      0.51        92\n",
      "weighted avg       0.55      0.57      0.54        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.69      0.61        39\n",
      "           2       0.60      0.56      0.58        32\n",
      "           3       0.31      0.19      0.24        21\n",
      "\n",
      "    accuracy                           0.53        92\n",
      "   macro avg       0.49      0.48      0.48        92\n",
      "weighted avg       0.51      0.53      0.52        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.72      0.67        39\n",
      "           2       0.43      0.31      0.36        32\n",
      "           3       0.17      0.19      0.18        21\n",
      "\n",
      "    accuracy                           0.46        92\n",
      "   macro avg       0.41      0.41      0.40        92\n",
      "weighted avg       0.45      0.46      0.45        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.79      0.66        39\n",
      "           2       0.59      0.31      0.41        32\n",
      "           3       0.30      0.29      0.29        21\n",
      "\n",
      "    accuracy                           0.51        92\n",
      "   macro avg       0.48      0.46      0.45        92\n",
      "weighted avg       0.51      0.51      0.49        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.77      0.62        39\n",
      "           2       0.50      0.31      0.38        32\n",
      "           3       0.27      0.19      0.22        21\n",
      "\n",
      "    accuracy                           0.48        92\n",
      "   macro avg       0.43      0.42      0.41        92\n",
      "weighted avg       0.46      0.48      0.45        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.67      0.60        39\n",
      "           2       0.64      0.50      0.56        32\n",
      "           3       0.25      0.24      0.24        21\n",
      "\n",
      "    accuracy                           0.51        92\n",
      "   macro avg       0.48      0.47      0.47        92\n",
      "weighted avg       0.51      0.51      0.51        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.67      0.60        39\n",
      "           2       0.60      0.38      0.46        32\n",
      "           3       0.33      0.38      0.36        21\n",
      "\n",
      "    accuracy                           0.50        92\n",
      "   macro avg       0.49      0.47      0.47        92\n",
      "weighted avg       0.51      0.50      0.50        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy and other metrics\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "target_names = ['melanoma', 'bcc', 'scc']\n",
    "\n",
    "# Variables for average classification report\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "#Make our customer score\n",
    "def classification_report_with_accuracy_score(y_test, y_pred):\n",
    "    originalclass.extend(y_test)\n",
    "    predictedclass.extend(y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy_score(y_test, y_pred) # return accuracy score\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(estimator = nb, X = X, y = Y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melanoma       0.57      0.75      0.65       391\n",
      "         bcc       0.59      0.39      0.47       323\n",
      "         scc       0.31      0.28      0.30       207\n",
      "\n",
      "    accuracy                           0.52       921\n",
      "   macro avg       0.49      0.47      0.47       921\n",
      "weighted avg       0.52      0.52      0.50       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average values in classification report for all folds in a K-fold Cross-validation  \n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=23, p=3,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 23, metric = 'minkowski', p = 3, weights = 'distance')\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66, 10,  3],\n",
       "       [22, 33,  5],\n",
       "       [16, 19, 11]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set result\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm2 = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6534801925212884\n"
     ]
    }
   ],
   "source": [
    "# Applying K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = knn, X = X_train, y = y_train, cv = 10)\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n",
      "{'metric': 'minkowski', 'n_neighbors': 23, 'p': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Applying Grid Search to Find the Best Hyperparameter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "    {'n_neighbors': [21, 23, 25, 27, 29], 'weights': ['uniform', 'distance'], 'p': [1, 2, 3], 'metric': ['minkowski']},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = knn, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(round(best_accuracy, 2))\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.65      0.61        40\n",
      "           2       0.44      0.56      0.49        32\n",
      "           3       0.29      0.10      0.14        21\n",
      "\n",
      "    accuracy                           0.49        93\n",
      "   macro avg       0.43      0.44      0.42        93\n",
      "weighted avg       0.46      0.49      0.47        93\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.79      0.71        39\n",
      "           2       0.66      0.76      0.70        33\n",
      "           3       0.50      0.15      0.23        20\n",
      "\n",
      "    accuracy                           0.64        92\n",
      "   macro avg       0.60      0.57      0.55        92\n",
      "weighted avg       0.62      0.64      0.60        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.85      0.74        39\n",
      "           2       0.67      0.67      0.67        33\n",
      "           3       0.78      0.35      0.48        20\n",
      "\n",
      "    accuracy                           0.67        92\n",
      "   macro avg       0.70      0.62      0.63        92\n",
      "weighted avg       0.69      0.67      0.66        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.79      0.70        39\n",
      "           2       0.57      0.61      0.59        33\n",
      "           3       0.57      0.20      0.30        20\n",
      "\n",
      "    accuracy                           0.60        92\n",
      "   macro avg       0.59      0.53      0.53        92\n",
      "weighted avg       0.59      0.60      0.57        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.64      0.63        39\n",
      "           2       0.54      0.69      0.60        32\n",
      "           3       0.27      0.14      0.19        21\n",
      "\n",
      "    accuracy                           0.54        92\n",
      "   macro avg       0.48      0.49      0.47        92\n",
      "weighted avg       0.51      0.54      0.52        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.64      0.62        39\n",
      "           2       0.50      0.47      0.48        32\n",
      "           3       0.45      0.43      0.44        21\n",
      "\n",
      "    accuracy                           0.53        92\n",
      "   macro avg       0.52      0.51      0.51        92\n",
      "weighted avg       0.53      0.53      0.53        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.77      0.68        39\n",
      "           2       0.60      0.56      0.58        32\n",
      "           3       0.38      0.24      0.29        21\n",
      "\n",
      "    accuracy                           0.58        92\n",
      "   macro avg       0.53      0.52      0.52        92\n",
      "weighted avg       0.56      0.58      0.56        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.69      0.61        39\n",
      "           2       0.56      0.56      0.56        32\n",
      "           3       0.18      0.10      0.12        21\n",
      "\n",
      "    accuracy                           0.51        92\n",
      "   macro avg       0.43      0.45      0.43        92\n",
      "weighted avg       0.47      0.51      0.48        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.72      0.65        39\n",
      "           2       0.58      0.66      0.62        32\n",
      "           3       0.44      0.19      0.27        21\n",
      "\n",
      "    accuracy                           0.58        92\n",
      "   macro avg       0.54      0.52      0.51        92\n",
      "weighted avg       0.56      0.58      0.55        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.67      0.63        39\n",
      "           2       0.56      0.69      0.62        32\n",
      "           3       0.60      0.29      0.39        21\n",
      "\n",
      "    accuracy                           0.59        92\n",
      "   macro avg       0.59      0.55      0.55        92\n",
      "weighted avg       0.59      0.59      0.57        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy and other metrics\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "target_names = ['melanoma', 'bcc', 'scc']\n",
    "\n",
    "# Variables for average classification report\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "#Make our customer score\n",
    "def classification_report_with_accuracy_score(y_test, y_pred):\n",
    "    originalclass.extend(y_test)\n",
    "    predictedclass.extend(y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy_score(y_test, y_pred) # return accuracy score\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(estimator = knn, X = X, y = Y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melanoma       0.61      0.72      0.66       391\n",
      "         bcc       0.57      0.62      0.59       323\n",
      "         scc       0.44      0.22      0.29       207\n",
      "\n",
      "    accuracy                           0.57       921\n",
      "   macro avg       0.54      0.52      0.51       921\n",
      "weighted avg       0.56      0.57      0.55       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average values in classification report for all folds in a K-fold Cross-validation  \n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation of Support Vector Machine (SVM)\n",
    "# Fitting SVM to the training set\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(C = 10, kernel = 'rbf', gamma = 0.01, random_state = 0)\n",
    "#classifier = SVC(C = 1, kernel = 'poly', degree = 30, random_state = 0)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71,  7,  1],\n",
       "       [17, 37,  6],\n",
       "       [ 5, 21, 20]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set result\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm2 = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6915216586449462\n"
     ]
    }
   ],
   "source": [
    "# Applying K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = svm, X = X_train, y = y_train, cv = 10)\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69\n",
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Applying Grid Search to Find the Best Hyperparameter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "    {'C': [1, 10, 100], 'kernel': ['rbf', 'sigmoid', 'poly'], 'gamma': [0.001, 0.01, 0.1, 10]},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = svm, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(round(best_accuracy, 2))\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.85      0.59        40\n",
      "           2       0.35      0.19      0.24        32\n",
      "           3       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.43        93\n",
      "   macro avg       0.60      0.35      0.28        93\n",
      "weighted avg       0.54      0.43      0.34        93\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.95      0.67        39\n",
      "           2       0.85      0.52      0.64        33\n",
      "           3       1.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.59        92\n",
      "   macro avg       0.79      0.49      0.44        92\n",
      "weighted avg       0.74      0.59      0.51        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.95      0.66        39\n",
      "           2       0.68      0.39      0.50        33\n",
      "           3       1.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.54        92\n",
      "   macro avg       0.73      0.45      0.39        92\n",
      "weighted avg       0.68      0.54      0.46        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.92      0.64        39\n",
      "           2       0.56      0.30      0.39        33\n",
      "           3       1.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.50        92\n",
      "   macro avg       0.68      0.41      0.34        92\n",
      "weighted avg       0.62      0.50      0.41        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.92      0.66        39\n",
      "           2       0.68      0.47      0.56        32\n",
      "           3       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.55        92\n",
      "   macro avg       0.73      0.46      0.41        92\n",
      "weighted avg       0.68      0.55      0.47        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.90      0.62        39\n",
      "           2       0.47      0.28      0.35        32\n",
      "           3       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.48        92\n",
      "   macro avg       0.65      0.39      0.33        92\n",
      "weighted avg       0.60      0.48      0.39        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.90      0.62        39\n",
      "           2       0.61      0.34      0.44        32\n",
      "           3       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.50        92\n",
      "   macro avg       0.69      0.41      0.35        92\n",
      "weighted avg       0.64      0.50      0.42        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.87      0.61        39\n",
      "           2       0.50      0.31      0.38        32\n",
      "           3       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.48        92\n",
      "   macro avg       0.66      0.39      0.33        92\n",
      "weighted avg       0.60      0.48      0.39        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.85      0.61        39\n",
      "           2       0.64      0.44      0.52        32\n",
      "           3       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.51        92\n",
      "   macro avg       0.70      0.43      0.37        92\n",
      "weighted avg       0.65      0.51      0.44        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.92      0.64        39\n",
      "           2       0.58      0.34      0.43        32\n",
      "           3       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.51        92\n",
      "   macro avg       0.69      0.42      0.36        92\n",
      "weighted avg       0.64      0.51      0.42        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy and other metrics\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "target_names = ['melanoma', 'bcc', 'scc']\n",
    "\n",
    "# Variables for average classification report\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "#Make our customer score\n",
    "def classification_report_with_accuracy_score(y_test, y_pred):\n",
    "    originalclass.extend(y_test)\n",
    "    predictedclass.extend(y_pred)\n",
    "    print(classification_report(y_test, y_pred, zero_division = 0))\n",
    "    return accuracy_score(y_test, y_pred) # return accuracy score\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(estimator = svm, X = X, y = Y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melanoma       0.49      0.90      0.63       391\n",
      "         bcc       0.60      0.36      0.45       323\n",
      "         scc       0.00      0.00      0.00       207\n",
      "\n",
      "    accuracy                           0.51       921\n",
      "   macro avg       0.36      0.42      0.36       921\n",
      "weighted avg       0.42      0.51      0.43       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average values in classification report for all folds in a K-fold Cross-validation  \n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=20, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some important notes here, before running the Decision Tree Classifier, it's ok to not scale the features, as this model\n",
    "# does not work using euclidian distance, so it's fine as it is\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 20, random_state = 0, splitter = 'best')\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54, 16,  9],\n",
       "       [12, 34, 14],\n",
       "       [10, 18, 18]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set result\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm2 = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5584042947056644\n"
     ]
    }
   ],
   "source": [
    "# Applying K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = tree, X = X_train, y = y_train, cv = 10)\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56\n",
      "{'ccp_alpha': 0.0, 'criterion': 'gini', 'max_depth': 20, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Applying Grid Search to Find the Best Hyperparameter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "    {'criterion': ['entropy', 'gini'], 'splitter': ['best', 'random'], 'ccp_alpha': [0.0, 0.05, 0.1], 'max_depth': [10, 20, 30]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = tree, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(round(best_accuracy, 2))\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.70      0.73        40\n",
      "           2       0.40      0.38      0.39        32\n",
      "           3       0.23      0.29      0.26        21\n",
      "\n",
      "    accuracy                           0.49        93\n",
      "   macro avg       0.46      0.45      0.46        93\n",
      "weighted avg       0.52      0.49      0.50        93\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.72      0.75        39\n",
      "           2       0.55      0.52      0.53        33\n",
      "           3       0.24      0.30      0.27        20\n",
      "\n",
      "    accuracy                           0.55        92\n",
      "   macro avg       0.52      0.51      0.51        92\n",
      "weighted avg       0.58      0.55      0.57        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.67      0.70        39\n",
      "           2       0.53      0.64      0.58        33\n",
      "           3       0.41      0.35      0.38        20\n",
      "\n",
      "    accuracy                           0.59        92\n",
      "   macro avg       0.56      0.55      0.55        92\n",
      "weighted avg       0.59      0.59      0.59        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.74      0.72        39\n",
      "           2       0.55      0.52      0.53        33\n",
      "           3       0.26      0.25      0.26        20\n",
      "\n",
      "    accuracy                           0.55        92\n",
      "   macro avg       0.50      0.50      0.50        92\n",
      "weighted avg       0.55      0.55      0.55        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71        39\n",
      "           2       0.61      0.62      0.62        32\n",
      "           3       0.47      0.43      0.45        21\n",
      "\n",
      "    accuracy                           0.62        92\n",
      "   macro avg       0.59      0.59      0.59        92\n",
      "weighted avg       0.62      0.62      0.62        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.67      0.68        39\n",
      "           2       0.45      0.47      0.46        32\n",
      "           3       0.38      0.38      0.38        21\n",
      "\n",
      "    accuracy                           0.53        92\n",
      "   macro avg       0.51      0.51      0.51        92\n",
      "weighted avg       0.54      0.53      0.53        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.56      0.59        39\n",
      "           2       0.49      0.53      0.51        32\n",
      "           3       0.38      0.38      0.38        21\n",
      "\n",
      "    accuracy                           0.51        92\n",
      "   macro avg       0.49      0.49      0.49        92\n",
      "weighted avg       0.51      0.51      0.51        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.69      0.68        39\n",
      "           2       0.38      0.31      0.34        32\n",
      "           3       0.24      0.29      0.26        21\n",
      "\n",
      "    accuracy                           0.47        92\n",
      "   macro avg       0.43      0.43      0.43        92\n",
      "weighted avg       0.47      0.47      0.47        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.77      0.73        39\n",
      "           2       0.59      0.50      0.54        32\n",
      "           3       0.41      0.43      0.42        21\n",
      "\n",
      "    accuracy                           0.60        92\n",
      "   macro avg       0.57      0.57      0.56        92\n",
      "weighted avg       0.60      0.60      0.59        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.54      0.58        39\n",
      "           2       0.55      0.56      0.55        32\n",
      "           3       0.27      0.33      0.30        21\n",
      "\n",
      "    accuracy                           0.50        92\n",
      "   macro avg       0.48      0.48      0.48        92\n",
      "weighted avg       0.52      0.50      0.51        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy and other metrics\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "target_names = ['melanoma', 'bcc', 'scc']\n",
    "\n",
    "# Variables for average classification report\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "#Make our customer score\n",
    "def classification_report_with_accuracy_score(y_test, y_pred):\n",
    "    originalclass.extend(y_test)\n",
    "    predictedclass.extend(y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy_score(y_test, y_pred) # return accuracy score\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(estimator = tree, X = X, y = Y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melanoma       0.70      0.68      0.69       391\n",
      "         bcc       0.51      0.50      0.51       323\n",
      "         scc       0.32      0.34      0.33       207\n",
      "\n",
      "    accuracy                           0.54       921\n",
      "   macro avg       0.51      0.51      0.51       921\n",
      "weighted avg       0.55      0.54      0.54       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average values in classification report for all folds in a K-fold Cross-validation  \n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight='balanced_subsample', criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=250, n_jobs=None, oob_score=False,\n",
       "                       random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 250, max_depth = None, criterion = 'entropy', class_weight = 'balanced_subsample', random_state = 0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66, 11,  2],\n",
       "       [10, 45,  5],\n",
       "       [10, 20, 16]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set result\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm2 = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6657904479822288\n"
     ]
    }
   ],
   "source": [
    "# Applying K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = forest, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n",
      "{'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "# Applying Grid Search to Find the Best Hyperparameter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "    {'criterion': ['entropy'], 'max_depth': [None], 'n_estimators': [150, 200, 250], 'class_weight': [None, 'balanced', 'balanced_subsample']},\n",
    "    {'criterion': ['gini'], 'max_depth': [None], 'n_estimators': [150, 200, 250], 'class_weight': [None, 'balanced', 'balanced_subsample']}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = forest, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(round(best_accuracy, 2))\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.85      0.84        40\n",
      "           2       0.56      0.75      0.64        32\n",
      "           3       0.44      0.19      0.27        21\n",
      "\n",
      "    accuracy                           0.67        93\n",
      "   macro avg       0.61      0.60      0.58        93\n",
      "weighted avg       0.65      0.67      0.64        93\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.87      0.84        39\n",
      "           2       0.72      0.85      0.78        33\n",
      "           3       0.73      0.40      0.52        20\n",
      "\n",
      "    accuracy                           0.76        92\n",
      "   macro avg       0.75      0.71      0.71        92\n",
      "weighted avg       0.76      0.76      0.75        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.82      0.79        39\n",
      "           2       0.68      0.85      0.76        33\n",
      "           3       0.44      0.20      0.28        20\n",
      "\n",
      "    accuracy                           0.70        92\n",
      "   macro avg       0.63      0.62      0.61        92\n",
      "weighted avg       0.66      0.70      0.67        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.85      0.79        39\n",
      "           2       0.59      0.67      0.63        33\n",
      "           3       0.40      0.20      0.27        20\n",
      "\n",
      "    accuracy                           0.64        92\n",
      "   macro avg       0.58      0.57      0.56        92\n",
      "weighted avg       0.61      0.64      0.62        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.79      0.78        39\n",
      "           2       0.64      0.78      0.70        32\n",
      "           3       0.54      0.33      0.41        21\n",
      "\n",
      "    accuracy                           0.68        92\n",
      "   macro avg       0.65      0.64      0.63        92\n",
      "weighted avg       0.67      0.68      0.67        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.79      0.82        39\n",
      "           2       0.66      0.72      0.69        32\n",
      "           3       0.70      0.67      0.68        21\n",
      "\n",
      "    accuracy                           0.74        92\n",
      "   macro avg       0.73      0.73      0.73        92\n",
      "weighted avg       0.74      0.74      0.74        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.87      0.79        39\n",
      "           2       0.59      0.69      0.64        32\n",
      "           3       0.50      0.19      0.28        21\n",
      "\n",
      "    accuracy                           0.65        92\n",
      "   macro avg       0.61      0.58      0.57        92\n",
      "weighted avg       0.63      0.65      0.62        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.74      0.70        39\n",
      "           2       0.60      0.66      0.63        32\n",
      "           3       0.38      0.24      0.29        21\n",
      "\n",
      "    accuracy                           0.60        92\n",
      "   macro avg       0.55      0.55      0.54        92\n",
      "weighted avg       0.58      0.60      0.58        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.85      0.78        39\n",
      "           2       0.65      0.75      0.70        32\n",
      "           3       0.78      0.33      0.47        21\n",
      "\n",
      "    accuracy                           0.70        92\n",
      "   macro avg       0.71      0.64      0.65        92\n",
      "weighted avg       0.71      0.70      0.68        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67        39\n",
      "           2       0.59      0.75      0.66        32\n",
      "           3       0.58      0.33      0.42        21\n",
      "\n",
      "    accuracy                           0.62        92\n",
      "   macro avg       0.61      0.58      0.58        92\n",
      "weighted avg       0.62      0.62      0.61        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy and other metrics\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "target_names = ['melanoma', 'bcc', 'scc']\n",
    "\n",
    "# Variables for average classification report\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "#Make our customer score\n",
    "def classification_report_with_accuracy_score(y_test, y_pred):\n",
    "    originalclass.extend(y_test)\n",
    "    predictedclass.extend(y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy_score(y_test, y_pred) # return accuracy score\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(estimator = forest, X = X, y = Y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melanoma       0.75      0.81      0.78       391\n",
      "         bcc       0.63      0.75      0.68       323\n",
      "         scc       0.56      0.31      0.40       207\n",
      "\n",
      "    accuracy                           0.68       921\n",
      "   macro avg       0.65      0.62      0.62       921\n",
      "weighted avg       0.66      0.68      0.66       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average values in classification report for all folds in a K-fold Cross-validation  \n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical input for predictor\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(handle_unknown='ignore')\n",
    "Y = Y.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_use = onehotencoder.fit_transform(Y).toarray()\n",
    "y_binary = onehotencoder.fit_transform(y_train).toarray()\n",
    "y_compare = onehotencoder.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.0621 - accuracy: 0.4620\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.9071 - accuracy: 0.5856\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.8338 - accuracy: 0.6318\n",
      "Epoch 4/100\n",
      "736/736 [==============================] - 0s 84us/step - loss: 0.7823 - accuracy: 0.6495\n",
      "Epoch 5/100\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.7473 - accuracy: 0.6685\n",
      "Epoch 6/100\n",
      "736/736 [==============================] - 0s 93us/step - loss: 0.7186 - accuracy: 0.6861\n",
      "Epoch 7/100\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.6862 - accuracy: 0.6902\n",
      "Epoch 8/100\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.6763 - accuracy: 0.6970\n",
      "Epoch 9/100\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.6581 - accuracy: 0.7065\n",
      "Epoch 10/100\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.6336 - accuracy: 0.7147\n",
      "Epoch 11/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.6187 - accuracy: 0.7201\n",
      "Epoch 12/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.6004 - accuracy: 0.7378\n",
      "Epoch 13/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.5819 - accuracy: 0.7582\n",
      "Epoch 14/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5873 - accuracy: 0.7405\n",
      "Epoch 15/100\n",
      "736/736 [==============================] - 0s 84us/step - loss: 0.5560 - accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.5449 - accuracy: 0.7636\n",
      "Epoch 17/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.5396 - accuracy: 0.7704\n",
      "Epoch 18/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5091 - accuracy: 0.7785\n",
      "Epoch 19/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5044 - accuracy: 0.7704\n",
      "Epoch 20/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.5111 - accuracy: 0.7745\n",
      "Epoch 21/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.4927 - accuracy: 0.7921\n",
      "Epoch 22/100\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.4811 - accuracy: 0.7948\n",
      "Epoch 23/100\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.4628 - accuracy: 0.8084\n",
      "Epoch 24/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.4637 - accuracy: 0.7989\n",
      "Epoch 25/100\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.4563 - accuracy: 0.8098 0s - loss: 0.4551 - accuracy: 0.80\n",
      "Epoch 26/100\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.4357 - accuracy: 0.8193\n",
      "Epoch 27/100\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.4369 - accuracy: 0.8057\n",
      "Epoch 28/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4250 - accuracy: 0.8315\n",
      "Epoch 29/100\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.4200 - accuracy: 0.8193\n",
      "Epoch 30/100\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.3968 - accuracy: 0.8329\n",
      "Epoch 31/100\n",
      "736/736 [==============================] - 0s 99us/step - loss: 0.3971 - accuracy: 0.8397\n",
      "Epoch 32/100\n",
      "736/736 [==============================] - 0s 93us/step - loss: 0.4147 - accuracy: 0.8125\n",
      "Epoch 33/100\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.3861 - accuracy: 0.8383\n",
      "Epoch 34/100\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3776 - accuracy: 0.8492\n",
      "Epoch 35/100\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.3511 - accuracy: 0.8519\n",
      "Epoch 36/100\n",
      "736/736 [==============================] - 0s 100us/step - loss: 0.3538 - accuracy: 0.8560\n",
      "Epoch 37/100\n",
      "736/736 [==============================] - 0s 111us/step - loss: 0.3476 - accuracy: 0.8668\n",
      "Epoch 38/100\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.3407 - accuracy: 0.8628\n",
      "Epoch 39/100\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.3343 - accuracy: 0.8614\n",
      "Epoch 40/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.3262 - accuracy: 0.8723\n",
      "Epoch 41/100\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.3094 - accuracy: 0.8832\n",
      "Epoch 42/100\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.3024 - accuracy: 0.8818\n",
      "Epoch 43/100\n",
      "736/736 [==============================] - 0s 107us/step - loss: 0.3040 - accuracy: 0.8804\n",
      "Epoch 44/100\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.3150 - accuracy: 0.8668\n",
      "Epoch 45/100\n",
      "736/736 [==============================] - 0s 93us/step - loss: 0.2976 - accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "736/736 [==============================] - 0s 107us/step - loss: 0.2927 - accuracy: 0.8832\n",
      "Epoch 47/100\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.2781 - accuracy: 0.8954\n",
      "Epoch 48/100\n",
      "736/736 [==============================] - 0s 99us/step - loss: 0.2540 - accuracy: 0.9090\n",
      "Epoch 49/100\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.2702 - accuracy: 0.9022\n",
      "Epoch 50/100\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.2427 - accuracy: 0.9117\n",
      "Epoch 51/100\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.2457 - accuracy: 0.9049\n",
      "Epoch 52/100\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.2283 - accuracy: 0.9226\n",
      "Epoch 53/100\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.2273 - accuracy: 0.9171\n",
      "Epoch 54/100\n",
      "736/736 [==============================] - 0s 93us/step - loss: 0.2320 - accuracy: 0.9062\n",
      "Epoch 55/100\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.2446 - accuracy: 0.9076\n",
      "Epoch 56/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.2119 - accuracy: 0.9171\n",
      "Epoch 57/100\n",
      "736/736 [==============================] - 0s 119us/step - loss: 0.2028 - accuracy: 0.9334\n",
      "Epoch 58/100\n",
      "736/736 [==============================] - 0s 104us/step - loss: 0.1849 - accuracy: 0.9361\n",
      "Epoch 59/100\n",
      "736/736 [==============================] - 0s 99us/step - loss: 0.1954 - accuracy: 0.9334\n",
      "Epoch 60/100\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.2140 - accuracy: 0.9198\n",
      "Epoch 61/100\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.1725 - accuracy: 0.9443\n",
      "Epoch 62/100\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.1775 - accuracy: 0.9429\n",
      "Epoch 63/100\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.2440 - accuracy: 0.9266\n",
      "Epoch 64/100\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.2167 - accuracy: 0.9293\n",
      "Epoch 65/100\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.1691 - accuracy: 0.9429\n",
      "Epoch 66/100\n",
      "736/736 [==============================] - 0s 104us/step - loss: 0.1668 - accuracy: 0.9429\n",
      "Epoch 67/100\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.1650 - accuracy: 0.9429\n",
      "Epoch 68/100\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.1540 - accuracy: 0.9552\n",
      "Epoch 69/100\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.1440 - accuracy: 0.9538\n",
      "Epoch 70/100\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.1305 - accuracy: 0.9606\n",
      "Epoch 71/100\n",
      "736/736 [==============================] - 0s 104us/step - loss: 0.1569 - accuracy: 0.94160s - loss: 0.1544 - accuracy: 0.94\n",
      "Epoch 72/100\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.1613 - accuracy: 0.9538\n",
      "Epoch 73/100\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.1957 - accuracy: 0.9375\n",
      "Epoch 74/100\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.1391 - accuracy: 0.9579\n",
      "Epoch 75/100\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.1291 - accuracy: 0.9647\n",
      "Epoch 76/100\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.1283 - accuracy: 0.9633\n",
      "Epoch 77/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.1352 - accuracy: 0.9620\n",
      "Epoch 78/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.1223 - accuracy: 0.9647\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 88us/step - loss: 0.0989 - accuracy: 0.9783\n",
      "Epoch 80/100\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.0839 - accuracy: 0.9837\n",
      "Epoch 81/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.0861 - accuracy: 0.9823\n",
      "Epoch 82/100\n",
      "736/736 [==============================] - 0s 93us/step - loss: 0.0841 - accuracy: 0.9851\n",
      "Epoch 83/100\n",
      "736/736 [==============================] - 0s 107us/step - loss: 0.0924 - accuracy: 0.9755\n",
      "Epoch 84/100\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.1296 - accuracy: 0.9565\n",
      "Epoch 85/100\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.1243 - accuracy: 0.9552\n",
      "Epoch 86/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.1700 - accuracy: 0.9511\n",
      "Epoch 87/100\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.0929 - accuracy: 0.9688\n",
      "Epoch 88/100\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.0773 - accuracy: 0.9810\n",
      "Epoch 89/100\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.0631 - accuracy: 0.9878\n",
      "Epoch 90/100\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.0784 - accuracy: 0.9810\n",
      "Epoch 91/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0864 - accuracy: 0.9783\n",
      "Epoch 92/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.0626 - accuracy: 0.9918\n",
      "Epoch 93/100\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.0547 - accuracy: 0.9905\n",
      "Epoch 94/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.0534 - accuracy: 0.9878\n",
      "Epoch 95/100\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.0490 - accuracy: 0.9905\n",
      "Epoch 96/100\n",
      "736/736 [==============================] - 0s 93us/step - loss: 0.0452 - accuracy: 0.9918\n",
      "Epoch 97/100\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.0438 - accuracy: 0.9946\n",
      "Epoch 98/100\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.0577 - accuracy: 0.9891\n",
      "Epoch 99/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.0635 - accuracy: 0.9837\n",
      "Epoch 100/100\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.0435 - accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23f4dd17a08>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the ANN\n",
    "ann = Sequential()\n",
    "\n",
    "# Adding the input & hidden layer\n",
    "ann.add(Dense(32, activation = 'relu', input_shape = (50,)))\n",
    "ann.add(Dense(32, activation = 'relu'))\n",
    "ann.add(Dense(32, activation = 'relu'))\n",
    "ann.add(Dense(3, activation = 'softmax'))\n",
    "ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_binary, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create threshold for multi-predictor\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70,  7,  2],\n",
       "       [ 9, 37, 14],\n",
       "       [ 6, 23, 17]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_compare.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64        40\n",
      "           1       0.42      0.69      0.52        32\n",
      "           2       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.52        93\n",
      "   macro avg       0.35      0.45      0.39        93\n",
      "weighted avg       0.42      0.52      0.46        93\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72        39\n",
      "           1       0.76      0.76      0.76        33\n",
      "           2       0.67      0.10      0.17        20\n",
      "\n",
      "    accuracy                           0.66        92\n",
      "   macro avg       0.68      0.58      0.55        92\n",
      "weighted avg       0.67      0.66      0.61        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68        39\n",
      "           1       0.65      0.79      0.71        33\n",
      "           2       0.42      0.25      0.31        20\n",
      "\n",
      "    accuracy                           0.63        92\n",
      "   macro avg       0.58      0.58      0.57        92\n",
      "weighted avg       0.61      0.63      0.61        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68        39\n",
      "           1       0.64      0.42      0.51        33\n",
      "           2       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.55        92\n",
      "   macro avg       0.39      0.46      0.40        92\n",
      "weighted avg       0.45      0.55      0.47        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67        39\n",
      "           1       0.55      0.69      0.61        32\n",
      "           2       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.57        92\n",
      "   macro avg       0.38      0.49      0.43        92\n",
      "weighted avg       0.44      0.57      0.50        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67        39\n",
      "           1       0.47      0.91      0.62        32\n",
      "           2       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.57        92\n",
      "   macro avg       0.41      0.50      0.43        92\n",
      "weighted avg       0.49      0.57      0.50        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.70        39\n",
      "           1       0.54      0.66      0.59        32\n",
      "           2       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.58        92\n",
      "   macro avg       0.38      0.49      0.43        92\n",
      "weighted avg       0.44      0.58      0.50        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60        39\n",
      "           1       0.47      0.53      0.50        32\n",
      "           2       0.25      0.10      0.14        21\n",
      "\n",
      "    accuracy                           0.49        92\n",
      "   macro avg       0.42      0.43      0.41        92\n",
      "weighted avg       0.45      0.49      0.46        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.79      0.65        39\n",
      "           1       0.62      0.62      0.62        32\n",
      "           2       0.33      0.05      0.08        21\n",
      "\n",
      "    accuracy                           0.57        92\n",
      "   macro avg       0.50      0.49      0.45        92\n",
      "weighted avg       0.52      0.57      0.51        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65        39\n",
      "           1       0.57      0.72      0.64        32\n",
      "           2       0.50      0.19      0.28        21\n",
      "\n",
      "    accuracy                           0.59        92\n",
      "   macro avg       0.56      0.53      0.52        92\n",
      "weighted avg       0.57      0.59      0.56        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy and other metrics\n",
    "#, scoring=make_scorer(classification_report_with_accuracy_score)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['melanoma', 'bcc', 'scc']\n",
    "\n",
    "# Variables for average classification report\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "#Build the Model\n",
    "def buildmodel():\n",
    "    ann = Sequential()\n",
    "    ann.add(Dense(16, activation = 'relu', input_shape = (50,)))\n",
    "    ann.add(Dense(16, activation = 'relu'))\n",
    "    ann.add(Dense(3, activation = 'softmax'))\n",
    "    ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'categorical_accuracy'])\n",
    "    return(ann)\n",
    "\n",
    "\n",
    "#Make our customer score\n",
    "def classification_report_with_accuracy_score(y_use, y_pred):\n",
    "    originalclass.extend(y_use)\n",
    "    predictedclass.extend(y_pred.argmax(axis=1))\n",
    "    print(classification_report(y_use, y_pred.argmax(axis=1)))\n",
    "    return accuracy_score(y_use, y_pred.argmax(axis=1)) # return accuracy score\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "ann = KerasRegressor(build_fn=buildmodel, epochs = 100, batch_size = 10, verbose = 0)\n",
    "nested_score = cross_val_score(estimator = ann, X = X, y = y_use.argmax(1), cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melanoma       0.60      0.75      0.67       391\n",
      "         bcc       0.55      0.68      0.61       323\n",
      "         scc       0.40      0.07      0.12       207\n",
      "\n",
      "    accuracy                           0.57       921\n",
      "   macro avg       0.52      0.50      0.46       921\n",
      "weighted avg       0.54      0.57      0.52       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average values in classification report for all folds in a K-fold Cross-validation  \n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              normalize_type='forest', nthread=None, objective='multi:softprob',\n",
       "              random_state=0, rate_drop=0.1, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, seed=None, silent=None, skip_drop=0.1,\n",
       "              subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the XGB Library and fit it to the data\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(objective = 'multi:softmax', booster = 'dart', n_estimators = 100, rate_drop = 0.1, max_depth = 3, normalize_type = 'forest', skip_drop = 0.1)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67,  9,  3],\n",
       "       [15, 40,  5],\n",
       "       [13, 22, 11]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set result\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm2 = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6480377637911885\n"
     ]
    }
   ],
   "source": [
    "# Applying K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = xgb, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n",
      "{'booster': 'dart', 'n_estimators': 100, 'normalize_type': 'forest', 'objective': 'multi:softmax', 'rate_drop': 0.1, 'sample_type': 'uniform', 'skip_drop': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Applying Grid Search to Find the Best Hyperparameter\n",
    "# {'objective': ['multi:softmax'], 'n_estimators': [25, 50, 100], 'booster': ['gbtree'], 'eta': [0.001, 0.002, 0.004], 'max_depth':[3], 'gamma': [0], 'subsample': [1], 'sampling_method': ['uniform', 'gradient_based']},\n",
    "# {'objective': ['multi:softmax'], 'n_estimators': [109], 'booster': ['dart'], 'sample_type': ['uniform', 'weighted'], 'normalize_type': ['tree', 'forest'], 'rate_drop': [0, 0.1, 0.2], 'skip_drop': [0, 0.1, 0.2]}\n",
    "# {'objective': ['multi:softmax'], 'n_estimators': [10, 25, 50], 'booster': ['gblinear'], 'feature_selector': ['greedy', 'cyclic', 'random', 'shuffle', 'thrifty'], 'updater': ['shotgun', 'coord_descent'], 'lambda': [0, 0.5, 1], 'alpha': [0, 0.5, 1]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "    {'objective': ['multi:softmax'], 'n_estimators': [25, 50, 100], 'booster': ['gbtree'], 'eta': [0.001, 0.002, 0.004], 'max_depth':[3], 'gamma': [0], 'subsample': [1], 'sampling_method': ['uniform', 'gradient_based']},\n",
    "    {'objective': ['multi:softmax'], 'n_estimators': [25, 50, 100], 'booster': ['dart'], 'sample_type': ['uniform', 'weighted'], 'normalize_type': ['tree', 'forest'], 'rate_drop': [0, 0.1, 0.2], 'skip_drop': [0, 0.1, 0.2]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgb, param_grid = parameters, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(round(best_accuracy, 2))\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.90      0.88        40\n",
      "           2       0.52      0.69      0.59        32\n",
      "           3       0.44      0.19      0.27        21\n",
      "\n",
      "    accuracy                           0.67        93\n",
      "   macro avg       0.61      0.59      0.58        93\n",
      "weighted avg       0.65      0.67      0.64        93\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.87      0.84        39\n",
      "           2       0.75      0.73      0.74        33\n",
      "           3       0.56      0.50      0.53        20\n",
      "\n",
      "    accuracy                           0.74        92\n",
      "   macro avg       0.71      0.70      0.70        92\n",
      "weighted avg       0.73      0.74      0.74        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.79      0.77        39\n",
      "           2       0.64      0.82      0.72        33\n",
      "           3       0.44      0.20      0.28        20\n",
      "\n",
      "    accuracy                           0.67        92\n",
      "   macro avg       0.61      0.60      0.59        92\n",
      "weighted avg       0.65      0.67      0.65        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.92      0.84        39\n",
      "           2       0.60      0.64      0.62        33\n",
      "           3       0.20      0.10      0.13        20\n",
      "\n",
      "    accuracy                           0.64        92\n",
      "   macro avg       0.52      0.55      0.53        92\n",
      "weighted avg       0.58      0.64      0.61        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.79      0.79        39\n",
      "           2       0.66      0.84      0.74        32\n",
      "           3       0.50      0.29      0.36        21\n",
      "\n",
      "    accuracy                           0.70        92\n",
      "   macro avg       0.65      0.64      0.63        92\n",
      "weighted avg       0.68      0.70      0.68        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.85      0.86        39\n",
      "           2       0.70      0.72      0.71        32\n",
      "           3       0.67      0.67      0.67        21\n",
      "\n",
      "    accuracy                           0.76        92\n",
      "   macro avg       0.74      0.74      0.74        92\n",
      "weighted avg       0.76      0.76      0.76        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.79      0.75        39\n",
      "           2       0.47      0.56      0.51        32\n",
      "           3       0.20      0.10      0.13        21\n",
      "\n",
      "    accuracy                           0.55        92\n",
      "   macro avg       0.46      0.48      0.46        92\n",
      "weighted avg       0.51      0.55      0.52        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.79      0.77        39\n",
      "           2       0.57      0.66      0.61        32\n",
      "           3       0.36      0.24      0.29        21\n",
      "\n",
      "    accuracy                           0.62        92\n",
      "   macro avg       0.56      0.56      0.56        92\n",
      "weighted avg       0.60      0.62      0.61        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.82      0.75        39\n",
      "           2       0.60      0.75      0.67        32\n",
      "           3       0.33      0.10      0.15        21\n",
      "\n",
      "    accuracy                           0.63        92\n",
      "   macro avg       0.54      0.56      0.52        92\n",
      "weighted avg       0.58      0.63      0.58        92\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.67      0.68        39\n",
      "           2       0.61      0.72      0.66        32\n",
      "           3       0.56      0.43      0.49        21\n",
      "\n",
      "    accuracy                           0.63        92\n",
      "   macro avg       0.62      0.60      0.61        92\n",
      "weighted avg       0.63      0.63      0.63        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy and other metrics\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "target_names = ['melanoma', 'bcc', 'scc']\n",
    "\n",
    "# Variables for average classification report\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "#Make our customer score\n",
    "def classification_report_with_accuracy_score(y_test, y_pred):\n",
    "    originalclass.extend(y_test)\n",
    "    predictedclass.extend(y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy_score(y_test, y_pred) # return accuracy score\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(estimator = xgb, X = X, y = Y, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    melanoma       0.77      0.82      0.79       391\n",
      "         bcc       0.61      0.71      0.66       323\n",
      "         scc       0.46      0.28      0.35       207\n",
      "\n",
      "    accuracy                           0.66       921\n",
      "   macro avg       0.61      0.60      0.60       921\n",
      "weighted avg       0.64      0.66      0.65       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average values in classification report for all folds in a K-fold Cross-validation  \n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
